{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import tweepy\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the downloaded file in a dataframe\n",
    "twitter_archive = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use requests library to download tsv file from a website\n",
    "url=\"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open('image_predictions.tsv', 'wb') as file:\n",
    "    file.write(response.content)\n",
    "    \n",
    "image_predictions = pd.read_csv('image_predictions.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Token key setup for twitter API\n",
    "ckey = 'zQd7Uq0i7FTfuAxy9rFm0OwF4'\n",
    "csecret = 'T6vl5Uf2ATJa2cKWrHIajtOrOqz2epkY1kNynupWXebxN5zfqi'\n",
    "atoken = '218933524-ig1iw9LIoGJZ0tqqrZYRAYBvC9rY382nj1fctw0M'\n",
    "asecret = 'OpHiMkgXeHKdyuIa6SY1z2S5F0ggMZY8PLWmb6BHgailC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authentications for twitter API\n",
    "auth = tweepy.OAuthHandler(ckey, csecret)\n",
    "auth.set_access_token(atoken, asecret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For loop to add each tweet to json file\n",
    "\n",
    "with open('tweet_json.txt', 'a', encoding='utf8') as f:\n",
    "    for tweet_id in twitter_archive['tweet_id']:\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            json.dump(tweet._json, f)\n",
    "            f.write('\\n')\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For loop to append each tweet in a list\n",
    "tweets_data = []\n",
    "\n",
    "tweet_file = open('tweet_json.txt', \"r\")\n",
    "\n",
    "for line in tweet_file:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "tweet_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tweet_info DataFrame\n",
    "tweet_info = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add selected variables to tweet_info DataFrame\n",
    "tweet_info['id'] = list(map(lambda tweet: tweet['id'], tweets_data))\n",
    "tweet_info['retweet_count'] = list(map(lambda tweet: tweet['retweet_count'], tweets_data))\n",
    "tweet_info['favorite_count'] = list(map(lambda tweet: tweet['favorite_count'], tweets_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_info.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving all files in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.to_csv('twitter_archive.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_info.to_csv('twitter_info.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.to_csv('image_predictions.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Loading all 3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive = pd.read_csv('twitter_archive.csv', sep = '\\t')\n",
    "image_predictions = pd.read_csv('image_predictions.csv', sep = '\\t')\n",
    "twitter_info = pd.read_csv('twitter_info.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['rating_denominator'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions['jpg_url'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_info['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_info['id'].value_counts()[twitter_info['id'].value_counts() > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive[twitter_archive['name'].str.islower()]['name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness\n",
    "\n",
    "- Three separate dataframes\n",
    "- Dog \"breed\" variable in four columns: doggo, floofer, pupper, puppo\n",
    "- Show entire text of twitter_archive.text\n",
    "\n",
    "#### Quality Issues\n",
    "- Name of Dog is None\n",
    "- Remove any retweets\n",
    "- Records with no images\n",
    "- Dog names consist of letters like a , an ,the etc\n",
    "- Some records have 0 rating in the denominator\n",
    "- Some rating in the denominator have values less than or more than 10. \n",
    "- Incorrect Numerator rating for some records.\n",
    "- Variables (timestamp and retweeted_status_timestamp) has object datatype it should be datetime\n",
    "- tweet_id is int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean = pd.read_csv('twitter_archive.csv', sep = '\\t', index_col=0)\n",
    "image_clean = pd.read_csv('image_predictions.csv', sep = '\\t', index_col=0)\n",
    "info_clean = pd.read_csv('twitter_info.csv', sep = '\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue 1:\n",
    "### Define\n",
    "Show entire text in archive_clean\n",
    "\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "archive_clean.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue 2:\n",
    "### Define\n",
    "Mergin all 3 dataframes to archive_clean dataframe\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean = pd.merge(left = archive_clean, right = info_clean, left_on = 'tweet_id', right_on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean = pd.merge(left = archive_clean, right = image_clean, on = 'tweet_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean = archive_clean.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue 3:\n",
    "### Define\n",
    "Making 1 column to store dog stages\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean['Stage'] = archive_clean['text'].str.extract('(puppo|pupper|floofer|doggo)', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping extra stage columns\n",
    "archive_clean = archive_clean.drop(['doggo', 'floofer', 'pupper', 'puppo'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue 4:\n",
    "### Define\n",
    "Discarding any retweets, we don't need any retweets\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean = archive_clean[archive_clean['retweeted_status_id'].isnull()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue 5:\n",
    "### Define\n",
    "Removing unnecessary retweeted columns\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean = archive_clean.drop(['retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue 6:\n",
    "### Define\n",
    "Remove rows with no images\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean = archive_clean.dropna(subset=['expanded_urls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue 7:\n",
    "### Define\n",
    "Changing the name of dogs from None to NAN\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean['name'] = archive_clean['name'].replace('None', np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean[archive_clean['name'].isnull()]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue 8:\n",
    "### Define\n",
    "Fixing dog names with 'a' , 'an', 'my', 'his'\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing an\n",
    "archive_clean['name'][1917] = 'Berta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing my\n",
    "archive_clean['name'][686] = 'Zoey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing a\n",
    "archive_clean['name'][1752] = 'Jacob'\n",
    "archive_clean['name'][1781] = 'Rufus'\n",
    "archive_clean['name'][1831] = 'Spork'\n",
    "archive_clean['name'][1840] = 'Cherokee'\n",
    "archive_clean['name'][1843] = 'Hemry'\n",
    "archive_clean['name'][1861] = 'Alfred'\n",
    "archive_clean['name'][1875] = 'Alfredo'\n",
    "archive_clean['name'][1905] = 'Leorio'\n",
    "archive_clean['name'][1930] = 'Chuk'\n",
    "archive_clean['name'][1947] = 'Alfonso'\n",
    "archive_clean['name'][1961] = 'Cheryl'\n",
    "archive_clean['name'][1967] = 'Jessiga'\n",
    "archive_clean['name'][1976] = 'Klint'\n",
    "archive_clean['name'][1985] = 'Kohl'\n",
    "archive_clean['name'][1999] = 'Daryl'\n",
    "archive_clean['name'][2015] = 'Pepe'\n",
    "archive_clean['name'][2022] = 'Octaviath'\n",
    "archive_clean['name'][2025] = 'Johm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing his\n",
    "archive_clean['name'][810] = 'Quizno'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean[archive_clean['name'].notnull()]['name'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue 9:\n",
    "### Define\n",
    "Inconsistent numerator and denominator\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean[archive_clean['rating_denominator'] == 2]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean['rating_numerator'][2046] = 9\n",
    "archive_clean['rating_denominator'][2046] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean[archive_clean['rating_denominator'] == 11]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean['rating_numerator'][872] = 14\n",
    "archive_clean['rating_denominator'][872] = 10\n",
    "archive_clean['rating_numerator'][1401] = 10\n",
    "archive_clean['rating_denominator'][1401] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 10:\n",
    "### Define\n",
    "Convert object variables (timestamp and retweeted_status_timestamp) to datetime and tweet_id to str\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.timestamp = pd.to_datetime(archive_clean.timestamp)\n",
    "archive_clean.tweet_id = archive_clean.tweet_id.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 11:\n",
    "### Define\n",
    "Converting Stage variable from object to categorical datatype\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.Stage = archive_clean.Stage.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue 12:\n",
    "### Define\n",
    "Replace all meaningless names with Nan\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean['name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meaningless_names = ['a', 'an', 'the', 'just', 'one', 'very', 'quite', 'not', 'actually', \n",
    "             'mad', 'space', 'infuriating', 'all', 'officially', '0', 'old', 'life',\n",
    "             'unacceptable', 'my', 'incredibly', 'by', 'his', 'such']\n",
    "\n",
    "for name in archive_clean['name']:\n",
    "    if name in meaningless_names:\n",
    "        archive_clean.name[archive_clean.name == name] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meaningless_names = ['a', 'an', 'the', 'just', 'one', 'very', 'quite', 'not', 'actually', \n",
    "             'mad', 'space', 'infuriating', 'all', 'officially', '0', 'old', 'life',\n",
    "             'unacceptable', 'my', 'incredibly', 'by', 'his', 'such']\n",
    "\n",
    "for name in archive_clean['name']:\n",
    "    if name in meaningless_names:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue 13:\n",
    "### Define\n",
    "Creating a new variable \"Rating\", by taking ratio of numerator and denomenator ratings\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean['Rating'] = archive_clean['rating_numerator'] / archive_clean['rating_denominator']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue 14:\n",
    "### Define\n",
    "Combining the dog breeds column to 1 column and only taking the dog breed when its true\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dog_breeds = []\n",
    "for n1,d1,n2,d2,n3,d3 in zip(archive_clean['p1'],archive_clean['p1_dog'],archive_clean['p2'],archive_clean['p2_dog'],archive_clean['p3'],archive_clean['p3_dog'] ):\n",
    "    if d1 == True:\n",
    "        Dog_breeds.append(n1)\n",
    "    elif d1 == False and d2 == True:\n",
    "        Dog_breeds.append(n2)\n",
    "    elif d1 == False and d2 == False and d3 == True:\n",
    "        Dog_breeds.append(n3)\n",
    "    else:\n",
    "        Dog_breeds.append(np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Removing unnecessary columns\n",
    "archive_clean = archive_clean.drop(['p1', 'p1_conf', 'p1_dog','p2', 'p2_conf', 'p2_dog','p3', 'p3_conf', 'p3_dog'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.to_csv('twitter_archive_master.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze & Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   0.1       ,   0.2       ,   0.3       ,\n",
       "         0.4       ,   0.5       ,   0.6       ,   0.7       ,\n",
       "         0.8       ,   0.9       ,   1.        ,   1.1       ,\n",
       "         1.2       ,   1.3       ,   1.4       ,   2.6       ,\n",
       "         2.7       ,   3.42857143,   7.5       ,  42.        ,\n",
       "       177.6       ])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "np.sort(archive_clean.Rating.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I have shown  3 visualizations and Analysis via a Tableau Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
